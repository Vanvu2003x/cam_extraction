import cv2
from ultralytics import YOLO
from dotenv import load_dotenv
import os
import threading
import queue
from fire_alert import fire_alert
from connect_camera import build_rtsp_url

# 1ï¸âƒ£ Äá»ŒC Cáº¤U HÃŒNH Tá»ª FILE .env
env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ".env")
load_dotenv(dotenv_path=env_path)

username = os.getenv("RTSP_USERNAME", "")
password = os.getenv("RTSP_PASSWORD", "")
ip = os.getenv("RTSP_IP", "")
port = os.getenv("RTSP_PORT", "554")
path = os.getenv("RTSP_PATH", "")

# 2ï¸âƒ£ Táº¢I MÃ” HÃŒNH YOLO
model = YOLO("../models/best.pt")  

# 3ï¸âƒ£ Káº¾T Ná»I CAMERA
rtsp_url = build_rtsp_url(
    username=username,
    password=password,
    ip=ip,
    port=port,
    channel=1,
    subtype=0
)
print("ğŸ”— Káº¿t ná»‘i tá»›i camera:", rtsp_url)

# Má»Ÿ camera RTSP
cap = cv2.VideoCapture(rtsp_url)

# 4ï¸âƒ£ Táº O HÃ€NG Äá»¢I
# frame_queue: LÆ°u frame tá»« camera 
# result_queue: LÆ°u káº¿t quáº£ inference (frame + results)
frame_queue = queue.Queue(maxsize=5)
result_queue = queue.Queue(maxsize=5)

def capture_frames():
    """
    Luá»“ng nÃ y chá»‰ Ä‘á»c frame tá»« camera vÃ  Ä‘áº©y vÃ o frame_queue.
    Náº¿u queue Ä‘áº§y, bá» frame cÅ© nháº¥t Ä‘á»ƒ trÃ¡nh delay.
    """
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âŒ KhÃ´ng láº¥y Ä‘Æ°á»£c frame tá»« camera")
            break

        if frame_queue.full():
            try:
                frame_queue.get_nowait()
            except queue.Empty:
                pass

        frame_queue.put(frame)

def ai_inference():
    """
    Luá»“ng nÃ y láº¥y frame tá»« frame_queue, cháº¡y YOLO, Ä‘Æ°a káº¿t quáº£ vÃ o result_queue.
    """
    while True:
        if not frame_queue.empty():
            frame = frame_queue.get()
            frame_resized = cv2.resize(frame, (640, 420))

            results = model(frame_resized) 

            if result_queue.full():
                try:
                    result_queue.get_nowait()
                except queue.Empty:
                    pass

            result_queue.put((frame, results))

# 7ï¸âƒ£ Táº O VÃ€ CHáº Y THREADS
capture_thread = threading.Thread(target=capture_frames, daemon=True)
capture_thread.start()

ai_thread = threading.Thread(target=ai_inference, daemon=True)
ai_thread.start()

# 8ï¸âƒ£ LUá»’NG CHÃNH: HIá»‚N THá»Š + Cáº¢NH BÃO (CPU)
print("ğŸš€ Báº¯t Ä‘áº§u phÃ¡t hiá»‡n Ä‘Ã¡m chÃ¡y... (nháº¥n 'q' Ä‘á»ƒ thoÃ¡t)")

while True:
    if not result_queue.empty():
        frame, results = result_queue.get()

        # Váº½ khung bounding box
        annotated_frame = results[0].plot()

        # Ghi chá»¯ tráº¡ng thÃ¡i
        fire_detected = len(results[0].boxes) > 0
        status_text = "ğŸ”¥ Fire detected!" if fire_detected else "âœ… No fire"
        color = (0, 0, 255) if fire_detected else (0, 255, 0)
        cv2.putText(annotated_frame, status_text, (20, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)

        # Hiá»ƒn thá»‹
        cv2.imshow("Fire Detection", annotated_frame)

        # Gá»­i tÃ­n hiá»‡u cáº£nh bÃ¡o
        fire_alert(fire_detected)

    # Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 9ï¸âƒ£ Dá»ŒN Dáº¸P
cap.release()
cv2.destroyAllWindows()
print("ğŸ›‘ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh.")
